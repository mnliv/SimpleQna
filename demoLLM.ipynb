{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145ffb4f-a391-4d8d-9dab-7576455c03d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/fa/7c/2165c25b08cce00d7271c03f4f35897a86853040fb2d1d99ef0182f9b164/langchain-0.0.301-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.301-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (6.0)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Obtaining dependency information for SQLAlchemy<3,>=1.4 from https://files.pythonhosted.org/packages/31/f6/3a2ccb16aae346eccc11836ac7188be1da12591bf19834826ae63b051f23/SQLAlchemy-2.0.21-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.21-cp310-cp310-win_amd64.whl.metadata (9.7 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Obtaining dependency information for aiohttp<4.0.0,>=3.8.3 from https://files.pythonhosted.org/packages/67/35/84691e1f705b1ec4ec583e27c04e0e9672dffadb86fbbd98bc3d8942f6c2/aiohttp-3.8.5-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading aiohttp-3.8.5-cp310-cp310-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (3.5.0)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Obtaining dependency information for async-timeout<5.0.0,>=4.0.0 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/13/75/82ce74880711ced796fd5a32e4d40c5a32dbea3f1c5e219a8b0544b7bd8c/dataclasses_json-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.38 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.38 from https://files.pythonhosted.org/packages/f5/2d/bca3d01bbc128aa9b5c0134ad5f53955aa84a5620b6b07769ba75f7ca96c/langsmith-0.0.40-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.40-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4 (from langchain)\n",
      "  Obtaining dependency information for numexpr<3.0.0,>=2.8.4 from https://files.pythonhosted.org/packages/13/90/6ad47a1f46340196e703c07882017c7f9514f30da5263a5c3d43122598b9/numexpr-2.8.6-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading numexpr-2.8.6-cp310-cp310-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (1.25.2)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Obtaining dependency information for pydantic<3,>=1 from https://files.pythonhosted.org/packages/f9/3e/2c5b1c8c7b0079eea7191f6b5b804d47db433e4e4e229b90455d4af7226d/pydantic-2.4.0-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.4.0-py3-none-any.whl.metadata (156 kB)\n",
      "     ---------------------------------------- 0.0/156.4 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/156.4 kB ? eta -:--:--\n",
      "     --------- --------------------------- 41.0/156.4 kB 653.6 kB/s eta 0:00:01\n",
      "     ------------------- ----------------- 81.9/156.4 kB 762.6 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 122.9/156.4 kB 804.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ 156.4/156.4 kB 849.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Obtaining dependency information for tenacity<9.0.0,>=8.1.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     -------------------- ------------------- 30.7/61.0 kB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 61.0/61.0 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/ad/1a/0035d6dd5e51580c060f80ac6819f0ea55da2b1f2dad8ad15f5d3e50d91c/frozenlist-1.4.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from anyio<4.0->langchain) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Obtaining dependency information for jsonpointer>=1.9 from https://files.pythonhosted.org/packages/12/f6/0232cc0c617e195f06f810534d00b74d2f348fe71b2118009ad8ad31f878/jsonpointer-2.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/d8/f0/a2ee543a96cc624c35a9086f39b1ed2aa403c6d355dfe47a11ee5c64a164/annotated_types-0.5.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pydantic-core==2.10.0 (from pydantic<3,>=1->langchain)\n",
      "  Obtaining dependency information for pydantic-core==2.10.0 from https://files.pythonhosted.org/packages/c7/80/ce67780d8d579af1eb841c10035a4d58be47c77443dad6e15e095f273a00/pydantic_core-2.10.0-cp310-none-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.10.0-cp310-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-2.0.2-cp310-cp310-win_amd64.whl (192 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading langchain-0.0.301-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.7 MB 991.0 kB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.7 MB 1.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.7 MB 1.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.3/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.4/1.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.6/1.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.7/1.7 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.2/1.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.8.5-cp310-cp310-win_amd64.whl (323 kB)\n",
      "   ---------------------------------------- 0.0/323.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 323.1/323.1 kB 10.1 MB/s eta 0:00:00\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading dataclasses_json-0.6.0-py3-none-any.whl (27 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.0.40-py3-none-any.whl (39 kB)\n",
      "Downloading numexpr-2.8.6-cp310-cp310-win_amd64.whl (94 kB)\n",
      "   ---------------------------------------- 0.0/95.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 95.0/95.0 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.4.0-py3-none-any.whl (395 kB)\n",
      "   ---------------------------------------- 0.0/395.4 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 327.7/395.4 kB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 395.4/395.4 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.10.0-cp310-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/2.0 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.8/2.0 MB 10.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/2.0 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.9/2.0 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.21-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.0 MB 15.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.0 MB 15.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.7/2.0 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.0 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.3/2.0 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Downloading frozenlist-1.4.0-cp310-cp310-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.4/44.4 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.4/49.4 kB ? eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: tenacity, pydantic-core, numexpr, mypy-extensions, multidict, marshmallow, jsonpointer, greenlet, frozenlist, async-timeout, annotated-types, yarl, typing-inspect, SQLAlchemy, pydantic, jsonpatch, aiosignal, langsmith, dataclasses-json, aiohttp, langchain\n",
      "Successfully installed SQLAlchemy-2.0.21 aiohttp-3.8.5 aiosignal-1.3.1 annotated-types-0.5.0 async-timeout-4.0.3 dataclasses-json-0.6.0 frozenlist-1.4.0 greenlet-2.0.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.301 langsmith-0.0.40 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 numexpr-2.8.6 pydantic-2.4.0 pydantic-core-2.10.0 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a99ba70-62a4-4377-9c6f-7818b252139d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Openai\n",
      "  Obtaining dependency information for Openai from https://files.pythonhosted.org/packages/ae/59/911d6e5f1d7514d79c527067643376cddcf4cb8d1728e599b3b03ab51c69/openai-0.28.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from Openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from Openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from Openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from requests>=2.20->Openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from requests>=2.20->Openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from requests>=2.20->Openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from requests>=2.20->Openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp->Openai) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp->Openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp->Openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp->Openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp->Openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp->Openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from tqdm->Openai) (0.4.6)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.5 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/76.5 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 30.7/76.5 kB 435.7 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 61.4/76.5 kB 465.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 76.5/76.5 kB 530.5 kB/s eta 0:00:00\n",
      "Installing collected packages: Openai\n",
      "Successfully installed Openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91589fbb-90a7-4064-b48b-68de7eccde96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface_hub) (3.12.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface_hub) (2023.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface_hub) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->huggingface_hub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->huggingface_hub) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c377b0-0e36-495d-907b-4ea2f07f7a77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd9621b8-477e-4829-9889-92ed004ed79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a1b0f4-ab70-493f-bda7-ccd3d2f75da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "527b1f67-225e-44a7-9567-3f37f7b76140",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m our_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the currency of India?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mour_query\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\langchain\\llms\\base.py:873\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[1;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    868\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(prompt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`generate` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 873\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    874\u001b[0m         [prompt],\n\u001b[0;32m    875\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    876\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    877\u001b[0m         tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    878\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    879\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    880\u001b[0m     )\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    883\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\langchain\\llms\\base.py:653\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    640\u001b[0m         )\n\u001b[0;32m    641\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    642\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    643\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m         )\n\u001b[0;32m    652\u001b[0m     ]\n\u001b[1;32m--> 653\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    654\u001b[0m         prompts, stop, run_managers, \u001b[38;5;28mbool\u001b[39m(new_arg_supported), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    655\u001b[0m     )\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\langchain\\llms\\base.py:541\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[0;32m    540\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    542\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\langchain\\llms\\base.py:528\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    520\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    525\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    527\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 528\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    529\u001b[0m                 prompts,\n\u001b[0;32m    530\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    531\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    532\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    533\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    534\u001b[0m             )\n\u001b[0;32m    535\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    536\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    537\u001b[0m         )\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\langchain\\llms\\openai.py:387\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m     choices\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    376\u001b[0m         {\n\u001b[0;32m    377\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation\u001b[38;5;241m.\u001b[39mtext,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m         }\n\u001b[0;32m    385\u001b[0m     )\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 387\u001b[0m     response \u001b[38;5;241m=\u001b[39m completion_with_retry(\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;28mself\u001b[39m, prompt\u001b[38;5;241m=\u001b[39m_prompts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    389\u001b[0m     )\n\u001b[0;32m    390\u001b[0m     choices\u001b[38;5;241m.\u001b[39mextend(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    391\u001b[0m     update_token_usage(_keys, response, token_usage)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\langchain\\llms\\openai.py:115\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _completion_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\tenacity\\__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[0;32m    388\u001b[0m     retry_state\u001b[38;5;241m.\u001b[39mprepare_for_next_attempt()\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\tenacity\\nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(seconds)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "our_query = \"What is the currency of India?\"\n",
    "completion = llm(our_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0908c22-1d75-4151-8f53-1c91055162df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d326a778-af17-4415-a7ec-907b5ba5dc3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\envs\\LLM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\ACER\\anaconda3\\envs\\LLM\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceHub(repo_id = \"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8aa0a-5962-4578-81d4-fbc3452874fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de639bfe-6e68-4c59-b4bf-26531fca240d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
